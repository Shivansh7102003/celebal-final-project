{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92e48866",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25791a74",
   "metadata": {},
   "source": [
    "#### 1.1 Import Data and Required Packages\n",
    "##### Importing Pandas, Numpy, Matplotlib, Seaborn and Warings Library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b080dfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "# Modelling\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, Ridge,Lasso\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45079ad",
   "metadata": {},
   "source": [
    "#### Import the CSV Data as Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e11c6255",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('stud.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20634923",
   "metadata": {},
   "source": [
    "#### Show Top 5 Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7e412a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race_ethnicity</th>\n",
       "      <th>parental_level_of_education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test_preparation_course</th>\n",
       "      <th>math_score</th>\n",
       "      <th>reading_score</th>\n",
       "      <th>writing_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>group A</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender race_ethnicity parental_level_of_education         lunch  \\\n",
       "0  female        group B           bachelor's degree      standard   \n",
       "1  female        group C                some college      standard   \n",
       "2  female        group B             master's degree      standard   \n",
       "3    male        group A          associate's degree  free/reduced   \n",
       "4    male        group C                some college      standard   \n",
       "\n",
       "  test_preparation_course  math_score  reading_score  writing_score  \n",
       "0                    none          72             72             74  \n",
       "1               completed          69             90             88  \n",
       "2                    none          90             95             93  \n",
       "3                    none          47             57             44  \n",
       "4                    none          76             78             75  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd32281",
   "metadata": {},
   "source": [
    "#### Preparing X and Y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56d72fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['math_score'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd613177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race_ethnicity</th>\n",
       "      <th>parental_level_of_education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test_preparation_course</th>\n",
       "      <th>reading_score</th>\n",
       "      <th>writing_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>group A</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender race_ethnicity parental_level_of_education         lunch  \\\n",
       "0  female        group B           bachelor's degree      standard   \n",
       "1  female        group C                some college      standard   \n",
       "2  female        group B             master's degree      standard   \n",
       "3    male        group A          associate's degree  free/reduced   \n",
       "4    male        group C                some college      standard   \n",
       "\n",
       "  test_preparation_course  reading_score  writing_score  \n",
       "0                    none             72             74  \n",
       "1               completed             90             88  \n",
       "2                    none             95             93  \n",
       "3                    none             57             44  \n",
       "4                    none             78             75  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f237ea14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories in 'gender' variable:      ['female' 'male']\n",
      "Categories in 'race_ethnicity' variable:   ['group B' 'group C' 'group A' 'group D' 'group E']\n",
      "Categories in'parental level of education' variable: [\"bachelor's degree\" 'some college' \"master's degree\" \"associate's degree\"\n",
      " 'high school' 'some high school']\n",
      "Categories in 'lunch' variable:      ['standard' 'free/reduced']\n",
      "Categories in 'test preparation course' variable:      ['none' 'completed']\n"
     ]
    }
   ],
   "source": [
    "print(\"Categories in 'gender' variable:     \",end=\" \" )\n",
    "print(df['gender'].unique())\n",
    "\n",
    "print(\"Categories in 'race_ethnicity' variable:  \",end=\" \")\n",
    "print(df['race_ethnicity'].unique())\n",
    "\n",
    "print(\"Categories in'parental level of education' variable:\",end=\" \" )\n",
    "print(df['parental_level_of_education'].unique())\n",
    "\n",
    "print(\"Categories in 'lunch' variable:     \",end=\" \" )\n",
    "print(df['lunch'].unique())\n",
    "\n",
    "print(\"Categories in 'test preparation course' variable:     \",end=\" \" )\n",
    "print(df['test_preparation_course'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "924b7f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['math_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffc69816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      72\n",
       "1      69\n",
       "2      90\n",
       "3      47\n",
       "4      76\n",
       "       ..\n",
       "995    88\n",
       "996    62\n",
       "997    59\n",
       "998    68\n",
       "999    77\n",
       "Name: math_score, Length: 1000, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e290fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Column Transformer with 3 types of transformers\n",
    "num_features = X.select_dtypes(exclude=\"object\").columns\n",
    "cat_features = X.select_dtypes(include=\"object\").columns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "oh_transformer = OneHotEncoder()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"OneHotEncoder\", oh_transformer, cat_features),\n",
    "         (\"StandardScaler\", numeric_transformer, num_features),        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c68f99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed5c4e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 7), (200, 7))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd80317",
   "metadata": {},
   "source": [
    "#### Create an Evaluate Function to give all metrics after model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c247bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true, predicted):\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    mse = mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(true, predicted))\n",
    "    r2_square = r2_score(true, predicted)\n",
    "    return mae, rmse, r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79ccb8e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from sklearn.base import clone\n",
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Import regressors\n",
    "# from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "# from xgboost import XGBRegressor\n",
    "# from catboost import CatBoostRegressor\n",
    "\n",
    "# def evaluate_model(y_true, y_pred):\n",
    "#     mae = mean_absolute_error(y_true, y_pred)\n",
    "#     rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "#     r2 = r2_score(y_true, y_pred)\n",
    "#     return mae, rmse, r2\n",
    "\n",
    "# def train_models_with_pipeline(X_train, y_train, X_test, y_test, preprocessor=None):\n",
    "#     \"\"\"\n",
    "#     Train multiple regression models with optional hyperparameter tuning\n",
    "    \n",
    "#     Parameters:\n",
    "#     - X_train, y_train: Training data\n",
    "#     - X_test, y_test: Test data\n",
    "#     - preprocessor: Optional preprocessor for pipeline (e.g., StandardScaler, ColumnTransformer)\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # If no preprocessor is provided, create a simple StandardScaler\n",
    "#     if preprocessor is None:\n",
    "#         preprocessor = StandardScaler()\n",
    "    \n",
    "#     # Define models\n",
    "#     models = {\n",
    "#         \"Linear Regression\": LinearRegression(),\n",
    "#         \"Lasso\": Lasso(),\n",
    "#         \"Ridge\": Ridge(),\n",
    "#         \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "#         \"Decision Tree\": DecisionTreeRegressor(),\n",
    "#         \"Random Forest Regressor\": RandomForestRegressor(),\n",
    "#         \"XGBRegressor\": XGBRegressor(verbosity=0),\n",
    "#         \"CatBoosting Regressor\": CatBoostRegressor(verbose=False),\n",
    "#         \"AdaBoost Regressor\": AdaBoostRegressor()\n",
    "#     }\n",
    "    \n",
    "#     # Define hyperparameter grids for RandomizedSearchCV\n",
    "#     param_grids = {\n",
    "#         \"Lasso\": {\n",
    "#             'regressor__alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "#         },\n",
    "#         \"Ridge\": {\n",
    "#             'regressor__alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "#         },\n",
    "#         \"K-Neighbors Regressor\": {\n",
    "#             'regressor__n_neighbors': [3, 5, 7, 9, 11, 15],\n",
    "#             'regressor__weights': ['uniform', 'distance'],\n",
    "#             'regressor__p': [1, 2]\n",
    "#         },\n",
    "#         \"Decision Tree\": {\n",
    "#             'regressor__max_depth': [None, 5, 10, 15, 20],\n",
    "#             'regressor__min_samples_split': [2, 5, 10],\n",
    "#             'regressor__min_samples_leaf': [1, 2, 4]\n",
    "#         },\n",
    "#         \"Random Forest Regressor\": {\n",
    "#             'regressor__n_estimators': [50, 100, 200],\n",
    "#             'regressor__max_depth': [None, 10, 20, 30],\n",
    "#             'regressor__min_samples_split': [2, 5, 10],\n",
    "#             'regressor__min_samples_leaf': [1, 2, 4]\n",
    "#         },\n",
    "#         \"XGBRegressor\": {\n",
    "#             'regressor__n_estimators': [100, 200, 300],\n",
    "#             'regressor__learning_rate': [0.01, 0.1, 0.3],\n",
    "#             'regressor__max_depth': [3, 5, 7],\n",
    "#             'regressor__subsample': [0.7, 0.8, 1.0]\n",
    "#         },\n",
    "#         \"CatBoosting Regressor\": {\n",
    "#             'regressor__iterations': [100, 200, 300],\n",
    "#             'regressor__learning_rate': [0.01, 0.1, 0.3],\n",
    "#             'regressor__depth': [4, 6, 8]\n",
    "#         },\n",
    "#         \"AdaBoost Regressor\": {\n",
    "#             'regressor__n_estimators': [50, 100, 200],\n",
    "#             'regressor__learning_rate': [0.01, 0.1, 1.0]\n",
    "#         }\n",
    "#     }\n",
    "    \n",
    "#     # Store results\n",
    "#     model_list = []\n",
    "#     r2_list = []\n",
    "#     results = {\n",
    "#         'model': [],\n",
    "#         'train_mae': [],\n",
    "#         'train_rmse': [],\n",
    "#         'train_r2': [],\n",
    "#         'test_mae': [],\n",
    "#         'test_rmse': [],\n",
    "#         'test_r2': [],\n",
    "#         'best_params': []\n",
    "#     }\n",
    "    \n",
    "#     best_models = {}\n",
    "    \n",
    "#     for name, model in models.items():\n",
    "#         print(f\"\\n{'='*50}\")\n",
    "#         print(f\"Training: {name}\")\n",
    "#         print('='*50)\n",
    "        \n",
    "#         # Create pipeline\n",
    "#         pipeline = Pipeline([\n",
    "#             ('preprocessor', preprocessor),\n",
    "#             ('regressor', model)\n",
    "#         ])\n",
    "        \n",
    "#         # Check if hyperparameter tuning is available for this model\n",
    "#         if name in param_grids:\n",
    "#             print(f\"→ Performing RandomizedSearchCV for {name}...\")\n",
    "            \n",
    "#             # Perform RandomizedSearchCV\n",
    "#             random_search = RandomizedSearchCV(\n",
    "#                 estimator=pipeline,\n",
    "#                 param_distributions=param_grids[name],\n",
    "#                 n_iter=20,  # Number of parameter settings sampled\n",
    "#                 cv=5,       # 5-fold cross-validation\n",
    "#                 scoring='r2',\n",
    "#                 n_jobs=-1,\n",
    "#                 random_state=42,\n",
    "#                 verbose=0\n",
    "#             )\n",
    "            \n",
    "#             # Fit the random search\n",
    "#             random_search.fit(X_train, y_train)\n",
    "            \n",
    "#             # Get the best model\n",
    "#             best_pipeline = random_search.best_estimator_\n",
    "#             best_params = random_search.best_params_\n",
    "            \n",
    "#             print(f\"✅ Best parameters: {best_params}\")\n",
    "#         else:\n",
    "#             # For models without hyperparameter tuning, just fit the pipeline\n",
    "#             pipeline.fit(X_train, y_train)\n",
    "#             best_pipeline = pipeline\n",
    "#             best_params = {}\n",
    "        \n",
    "#         # Make predictions\n",
    "#         y_train_pred = best_pipeline.predict(X_train)\n",
    "#         y_test_pred = best_pipeline.predict(X_test)\n",
    "        \n",
    "#         # Evaluate Train and Test dataset\n",
    "#         model_train_mae, model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
    "#         model_test_mae, model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "        \n",
    "#         # Store results\n",
    "#         model_list.append(name)\n",
    "#         r2_list.append(model_test_r2)\n",
    "#         best_models[name] = best_pipeline\n",
    "        \n",
    "#         results['model'].append(name)\n",
    "#         results['train_mae'].append(model_train_mae)\n",
    "#         results['train_rmse'].append(model_train_rmse)\n",
    "#         results['train_r2'].append(model_train_r2)\n",
    "#         results['test_mae'].append(model_test_mae)\n",
    "#         results['test_rmse'].append(model_test_rmse)\n",
    "#         results['test_r2'].append(model_test_r2)\n",
    "#         results['best_params'].append(best_params)\n",
    "        \n",
    "#         # Print results\n",
    "#         print('\\nModel performance for Training set')\n",
    "#         print(f\"- Root Mean Squared Error: {model_train_rmse:.4f}\")\n",
    "#         print(f\"- Mean Absolute Error: {model_train_mae:.4f}\")\n",
    "#         print(f\"- R2 Score: {model_train_r2:.4f}\")\n",
    "        \n",
    "#         print('----------------------------------')\n",
    "        \n",
    "#         print('Model performance for Test set')\n",
    "#         print(f\"- Root Mean Squared Error: {model_test_rmse:.4f}\")\n",
    "#         print(f\"- Mean Absolute Error: {model_test_mae:.4f}\")\n",
    "#         print(f\"- R2 Score: {model_test_r2:.4f}\")\n",
    "    \n",
    "#     # Create results DataFrame\n",
    "#     results_df = pd.DataFrame(results)\n",
    "#     results_df = results_df.sort_values('test_r2', ascending=False)\n",
    "    \n",
    "#     print(\"\\n\" + \"=\"*50)\n",
    "#     print(\"SUMMARY - Model Performance Ranking (by Test R2)\")\n",
    "#     print(\"=\"*50)\n",
    "#     print(results_df[['model', 'test_r2', 'test_rmse', 'test_mae']].to_string(index=False))\n",
    "    \n",
    "#     # Find best model\n",
    "#     best_model_name = results_df.iloc[0]['model']\n",
    "#     print(f\"\\n🏆 Best Model: {best_model_name} with R2 Score: {results_df.iloc[0]['test_r2']:.4f}\")\n",
    "    \n",
    "#     return results_df, best_models\n",
    "\n",
    "# # Example usage:\n",
    "# # If you have numerical and categorical features, you can create a preprocessor like this:\n",
    "# def create_preprocessor(numerical_features, categorical_features):\n",
    "#     \"\"\"\n",
    "#     Create a preprocessor for numerical and categorical features\n",
    "#     \"\"\"\n",
    "#     numerical_transformer = StandardScaler()\n",
    "#     categorical_transformer = OneHotEncoder(drop='first', sparse_output=False)\n",
    "    \n",
    "#     preprocessor = ColumnTransformer(\n",
    "#         transformers=[\n",
    "#             ('num', numerical_transformer, numerical_features),\n",
    "#             ('cat', categorical_transformer, categorical_features)\n",
    "#         ])\n",
    "    \n",
    "#     return preprocessor\n",
    "\n",
    "# results_df, best_models = train_models_with_pipeline(X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06480b5a",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3acf1fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Training: Linear Regression\n",
      "Model performance for Test set\n",
      "- R2 Score: 0.8804\n",
      "- RMSE: 5.3940\n",
      "- MAE: 4.2148\n",
      "==================================================\n",
      "Training: Lasso\n",
      "→ Performing RandomizedSearchCV for Lasso...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\final project\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 5 is smaller than n_iter=20. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best parameters: {'regressor__alpha': 0.001}\n",
      "Model performance for Test set\n",
      "- R2 Score: 0.8805\n",
      "- RMSE: 5.3930\n",
      "- MAE: 4.2137\n",
      "==================================================\n",
      "Training: Ridge\n",
      "→ Performing RandomizedSearchCV for Ridge...\n",
      "✅ Best parameters: {'regressor__alpha': 1.0}\n",
      "Model performance for Test set\n",
      "- R2 Score: 0.8806\n",
      "- RMSE: 5.3904\n",
      "- MAE: 4.2111\n",
      "==================================================\n",
      "Training: K-Neighbors Regressor\n",
      "→ Performing RandomizedSearchCV for K-Neighbors Regressor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\final project\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 5 is smaller than n_iter=20. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "e:\\final project\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 10 is smaller than n_iter=20. Running 10 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best parameters: {'regressor__weights': 'distance', 'regressor__n_neighbors': 15}\n",
      "Model performance for Test set\n",
      "- R2 Score: 0.7907\n",
      "- RMSE: 7.1362\n",
      "- MAE: 5.5406\n",
      "==================================================\n",
      "Training: Decision Tree\n",
      "→ Performing RandomizedSearchCV for Decision Tree...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\final project\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 12 is smaller than n_iter=20. Running 12 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best parameters: {'regressor__min_samples_split': 2, 'regressor__max_depth': 5}\n",
      "Model performance for Test set\n",
      "- R2 Score: 0.8242\n",
      "- RMSE: 6.5400\n",
      "- MAE: 4.9315\n",
      "==================================================\n",
      "Training: Random Forest Regressor\n",
      "→ Performing RandomizedSearchCV for Random Forest Regressor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\final project\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 9 is smaller than n_iter=20. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best parameters: {'regressor__n_estimators': 200, 'regressor__max_depth': 10}\n",
      "Model performance for Test set\n",
      "- R2 Score: 0.8528\n",
      "- RMSE: 5.9844\n",
      "- MAE: 4.6256\n",
      "==================================================\n",
      "Training: XGBRegressor\n",
      "→ Performing RandomizedSearchCV for XGBRegressor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\final project\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 18 is smaller than n_iter=20. Running 18 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best parameters: {'regressor__n_estimators': 100, 'regressor__max_depth': 3, 'regressor__learning_rate': 0.1}\n",
      "Model performance for Test set\n",
      "- R2 Score: 0.8683\n",
      "- RMSE: 5.6611\n",
      "- MAE: 4.3732\n",
      "==================================================\n",
      "Training: CatBoosting Regressor\n",
      "→ Performing RandomizedSearchCV for CatBoosting Regressor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\final project\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 12 is smaller than n_iter=20. Running 12 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best parameters: {'regressor__learning_rate': 0.1, 'regressor__iterations': 200, 'regressor__depth': 4}\n",
      "Model performance for Test set\n",
      "- R2 Score: 0.8729\n",
      "- RMSE: 5.5620\n",
      "- MAE: 4.2930\n",
      "==================================================\n",
      "Training: AdaBoost Regressor\n",
      "→ Performing RandomizedSearchCV for AdaBoost Regressor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\final project\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 6 is smaller than n_iter=20. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Best parameters: {'regressor__n_estimators': 100, 'regressor__learning_rate': 1.0}\n",
      "Model performance for Test set\n",
      "- R2 Score: 0.8539\n",
      "- RMSE: 5.9632\n",
      "- MAE: 4.6352\n",
      "\n",
      "==================================================\n",
      "SUMMARY - Model Performance Ranking (by Test R2)\n",
      "==================================================\n",
      "                  model  test_r2  test_rmse  test_mae\n",
      "                  Ridge 0.880592   5.390418  4.211113\n",
      "                  Lasso 0.880477   5.393004  4.213680\n",
      "      Linear Regression 0.880433   5.393994  4.214763\n",
      "  CatBoosting Regressor 0.872868   5.562026  4.293007\n",
      "           XGBRegressor 0.868297   5.661136  4.373195\n",
      "     AdaBoost Regressor 0.853867   5.963196  4.635230\n",
      "Random Forest Regressor 0.852829   5.984350  4.625578\n",
      "          Decision Tree 0.824230   6.540001  4.931523\n",
      "  K-Neighbors Regressor 0.790719   7.136248  5.540594\n",
      "\n",
      "🏆 Best Model: Ridge with R2 Score: 0.8806\n",
      "\n",
      "✅ Best model pipeline saved as: saved_models/best_model_pipeline.pkl\n",
      "This single file now contains everything needed for prediction.\n",
      "\n",
      "==================================================\n",
      "Saving feature information for the Streamlit app...\n",
      "✅ Feature information saved as: saved_models/feature_info.json\n"
     ]
    }
   ],
   "source": [
    "# This new block replaces the code in cells [14] and [15]\n",
    "\n",
    "# Import necessary libraries\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# --- 1. Define Models and Hyperparameter Grids ---\n",
    "# (This is the same as your original notebook)\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
    "    \"XGBRegressor\": XGBRegressor(verbosity=0),\n",
    "    \"CatBoosting Regressor\": CatBoostRegressor(verbose=False),\n",
    "    \"AdaBoost Regressor\": AdaBoostRegressor()\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    \"Lasso\": {'regressor__alpha': [0.001, 0.01, 0.1, 1.0, 10.0]},\n",
    "    \"Ridge\": {'regressor__alpha': [0.001, 0.01, 0.1, 1.0, 10.0]},\n",
    "    \"K-Neighbors Regressor\": {'regressor__n_neighbors': [3, 5, 7, 9, 15], 'regressor__weights': ['uniform', 'distance']},\n",
    "    \"Decision Tree\": {'regressor__max_depth': [None, 5, 10, 20], 'regressor__min_samples_split': [2, 5, 10]},\n",
    "    \"Random Forest Regressor\": {'regressor__n_estimators': [50, 100, 200], 'regressor__max_depth': [None, 10, 20]},\n",
    "    \"XGBRegressor\": {'regressor__n_estimators': [100, 200], 'regressor__learning_rate': [0.01, 0.1, 0.3], 'regressor__max_depth': [3, 5, 7]},\n",
    "    \"CatBoosting Regressor\": {'regressor__iterations': [100, 200], 'regressor__learning_rate': [0.01, 0.1], 'regressor__depth': [4, 6, 8]},\n",
    "    \"AdaBoost Regressor\": {'regressor__n_estimators': [50, 100], 'regressor__learning_rate': [0.01, 0.1, 1.0]}\n",
    "}\n",
    "\n",
    "# --- 2. Correct Training Loop ---\n",
    "# This loop builds a full pipeline with the *correct preprocessor* from cell [9]\n",
    "results = []\n",
    "best_models = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"==================================================\")\n",
    "    print(f\"Training: {name}\")\n",
    "    \n",
    "    # Create the full, correct pipeline\n",
    "    full_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor), # The ColumnTransformer from cell [9]\n",
    "        ('regressor', model)\n",
    "    ])\n",
    "\n",
    "    # Use RandomizedSearchCV if a parameter grid is defined\n",
    "    if name in param_grids:\n",
    "        print(f\"→ Performing RandomizedSearchCV for {name}...\")\n",
    "        random_search = RandomizedSearchCV(\n",
    "            estimator=full_pipeline,\n",
    "            param_distributions=param_grids[name],\n",
    "            n_iter=20, cv=5, scoring='r2', n_jobs=-1, random_state=42, error_score='raise'\n",
    "        )\n",
    "        # Fit on the raw training data (X_train is a DataFrame here)\n",
    "        random_search.fit(X_train, y_train)\n",
    "        best_pipeline = random_search.best_estimator_\n",
    "        print(f\"✅ Best parameters: {random_search.best_params_}\")\n",
    "    else:\n",
    "        # Fit the pipeline directly for models without hyperparameter tuning\n",
    "        best_pipeline = full_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the best pipeline on the test set\n",
    "    y_test_pred = best_pipeline.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    r2 = r2_score(y_test, y_test_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(f\"- R2 Score: {r2:.4f}\")\n",
    "    print(f\"- RMSE: {rmse:.4f}\")\n",
    "    print(f\"- MAE: {mae:.4f}\")\n",
    "    \n",
    "    # Store results and the final, correct pipeline object\n",
    "    results.append({'model': name, 'test_r2': r2, 'test_rmse': rmse, 'test_mae': mae})\n",
    "    best_models[name] = best_pipeline\n",
    "\n",
    "# --- 3. Rank Models and Save the Best One ---\n",
    "results_df = pd.DataFrame(results).sort_values('test_r2', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SUMMARY - Model Performance Ranking (by Test R2)\")\n",
    "print(\"=\"*50)\n",
    "print(results_df.to_string(index=False))\n",
    "# ADD THIS LINE TO SAVE THE RESULTS\n",
    "results_df.to_csv('saved_models/model_results.csv', index=False)\n",
    "# Get the best model\n",
    "best_model_name = results_df.iloc[0]['model']\n",
    "best_model_pipeline = best_models[best_model_name]\n",
    "\n",
    "print(f\"\\n🏆 Best Model: {best_model_name} with R2 Score: {results_df.iloc[0]['test_r2']:.4f}\")\n",
    "\n",
    "# Create directory for saving\n",
    "os.makedirs('saved_models', exist_ok=True)\n",
    "\n",
    "# Save the single, complete, and correct best model pipeline\n",
    "model_filename = 'saved_models/best_model_pipeline.pkl'\n",
    "joblib.dump(best_model_pipeline, model_filename)\n",
    "\n",
    "print(f\"\\n✅ Best model pipeline saved as: {model_filename}\")\n",
    "print(\"This single file now contains everything needed for prediction.\")\n",
    "\n",
    "# ADD THIS BLOCK TO THE END OF THE CELL\n",
    "\n",
    "import json\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Saving feature information for the Streamlit app...\")\n",
    "\n",
    "# Dynamically get feature names and their unique values from the original X dataframe\n",
    "categorical_features = X.select_dtypes(include='object').columns.tolist()\n",
    "numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "categorical_values = {col: sorted(X[col].unique().tolist()) for col in categorical_features}\n",
    "\n",
    "# Create the feature_info dictionary\n",
    "feature_info = {\n",
    "    'numerical_features': numerical_features,\n",
    "    'categorical_features': categorical_features,\n",
    "    'categorical_values': categorical_values,\n",
    "    'target_variable': 'math_score' # The actual target variable\n",
    "}\n",
    "\n",
    "# Save the feature_info dictionary as a JSON file\n",
    "feature_info_filename = 'saved_models/feature_info.json'\n",
    "with open(feature_info_filename, 'w') as f:\n",
    "    json.dump(feature_info, f, indent=4)\n",
    "\n",
    "print(f\"✅ Feature information saved as: {feature_info_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
